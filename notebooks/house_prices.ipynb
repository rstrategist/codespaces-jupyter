{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef58c482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
      "0    -122.23     37.88                41.0        880.0           129.0   \n",
      "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
      "2    -122.24     37.85                52.0       1467.0           190.0   \n",
      "3    -122.25     37.85                52.0       1274.0           235.0   \n",
      "4    -122.25     37.85                52.0       1627.0           280.0   \n",
      "\n",
      "   population  households  median_income  median_house_value ocean_proximity  \n",
      "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
      "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
      "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
      "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
      "4       565.0       259.0         3.8462            342200.0        NEAR BAY  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# 1. Load dataset\n",
    "url = \"https://raw.githubusercontent.com/ageron/handson-ml/master/datasets/housing/housing.csv\"\n",
    "df = pd.read_csv(url)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60ebebdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost -> RMSE: 47365.40, R²: 0.829\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000537 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1846\n",
      "[LightGBM] [Info] Number of data points in the train set: 16512, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 207194.693738\n",
      "LightGBM -> RMSE: 45699.72, R²: 0.841\n",
      "CatBoost -> RMSE: 48347.41, R²: 0.822\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2. Features & target\n",
    "X = df.drop(\"median_house_value\", axis=1)\n",
    "y = df[\"median_house_value\"]\n",
    "\n",
    "# Identify categorical and numerical features\n",
    "categorical = X.select_dtypes(include=[\"object\"]).columns\n",
    "numerical = X.select_dtypes(exclude=[\"object\"]).columns\n",
    "\n",
    "# 3. Preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numerical),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 4. Models\n",
    "models = {\n",
    "    \"XGBoost\": XGBRegressor(n_estimators=500, learning_rate=0.05, max_depth=6),\n",
    "    \"LightGBM\": LGBMRegressor(n_estimators=500, learning_rate=0.05, max_depth=-1),\n",
    "    \"CatBoost\": CatBoostRegressor(n_estimators=500, learning_rate=0.05, depth=6, verbose=0)\n",
    "}\n",
    "\n",
    "# 5. Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 6. Train and evaluate\n",
    "for name, model in models.items():\n",
    "    pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    preds = pipeline.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "    r2 = r2_score(y_test, preds)\n",
    "    print(f\"{name} -> RMSE: {rmse:.2f}, R²: {r2:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f098b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved run logs to logs/20250921_125610\n"
     ]
    }
   ],
   "source": [
    "import os, json, joblib\n",
    "from datetime import datetime\n",
    "\n",
    "# 1. Make logs directory\n",
    "os.makedirs(\"logs\", exist_ok=True)\n",
    "\n",
    "# 2. Timestamped run folder\n",
    "run_id = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "run_dir = f\"../logs/{run_id}\"\n",
    "os.makedirs(run_dir, exist_ok=True)\n",
    "\n",
    "# 3. Save metrics\n",
    "metrics = {\n",
    "    \"rmse\": rmse,\n",
    "    \"r2\": r2,\n",
    "    \"model\": name\n",
    "}\n",
    "with open(f\"{run_dir}/metrics.json\", \"w\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "# 4. Save trained model\n",
    "joblib.dump(pipeline, f\"{run_dir}/{name}_model.pkl\")\n",
    "\n",
    "print(f\"Saved run logs to {run_dir}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
